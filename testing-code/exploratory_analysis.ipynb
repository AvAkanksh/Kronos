{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8522d8c",
   "metadata": {},
   "source": [
    "# Exploratory Analysis of Kronos Model\n",
    "\n",
    "This notebook is for experimenting with the Kronos model. We will:\n",
    "1. Load the pre-trained Kronos model and tokenizer.\n",
    "2. Fetch financial data using `yfinance`.\n",
    "3. Use the model to make predictions on the fetched data.\n",
    "4. Visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a627d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2a701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import yfinance as yf\n",
    "\n",
    "# To import from parent directory\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from model import Kronos, KronosTokenizer, KronosPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8669e11",
   "metadata": {},
   "source": [
    "### 1. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba88515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-07T07:03:24.664633Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://cas-server.xethub.hf.co/reconstruction/37f0525a4e4797e437229dfddc6f9623eac479961a3f0313a6e2dcd0e96c6fc5\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Custom { kind: InvalidData, error: InvalidMessage(InvalidContentType) } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:226\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:24.664684Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 599.739365ms before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:32.364004Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://cas-server.xethub.hf.co/reconstruction/37f0525a4e4797e437229dfddc6f9623eac479961a3f0313a6e2dcd0e96c6fc5\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Custom { kind: InvalidData, error: InvalidMessage(InvalidContentType) } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:226\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:32.364063Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #1. Sleeping 3.539288411s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:43.097061Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://cas-server.xethub.hf.co/reconstruction/37f0525a4e4797e437229dfddc6f9623eac479961a3f0313a6e2dcd0e96c6fc5\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Custom { kind: InvalidData, error: InvalidMessage(InvalidContentType) } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:226\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:43.097086Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #2. Sleeping 2.431485113s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:52.718897Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://cas-server.xethub.hf.co/reconstruction/37f0525a4e4797e437229dfddc6f9623eac479961a3f0313a6e2dcd0e96c6fc5\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Custom { kind: InvalidData, error: InvalidMessage(InvalidContentType) } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:226\n",
      "\n",
      "  \u001b[2m2025-10-07T07:03:52.718929Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #3. Sleeping 23.878147666s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model = Kronos.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mNeoQuasar/Kronos-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Instantiate Predictor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m predictor = \u001b[43mKronosPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_context\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gitrepos/Kronos/testing-code/../model/kronos.py:469\u001b[39m, in \u001b[36mKronosPredictor.__init__\u001b[39m\u001b[34m(self, model, tokenizer, device, max_context, clip)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28mself\u001b[39m.time_cols = [\u001b[33m'\u001b[39m\u001b[33mminute\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweekday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28mself\u001b[39m.device = device\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.model.to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/base/lib/python3.13/site-packages/torch/nn/modules/module.py:1369\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1367\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/base/lib/python3.13/site-packages/torch/nn/modules/module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/base/lib/python3.13/site-packages/torch/nn/modules/module.py:955\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/base/lib/python3.13/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1349\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1350\u001b[39m             device,\n\u001b[32m   1351\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m             non_blocking,\n\u001b[32m   1353\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/base/lib/python3.13/site-packages/torch/cuda/__init__.py:412\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    411\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    416\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "# Load Model and Tokenizer\n",
    "tokenizer = KronosTokenizer.from_pretrained(\"NeoQuasar/Kronos-Tokenizer-base\")\n",
    "model = Kronos.from_pretrained(\"NeoQuasar/Kronos-small\")\n",
    "\n",
    "# Instantiate Predictor\n",
    "predictor = KronosPredictor(model, tokenizer, device=\"cuda:0\", max_context=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298d5fc",
   "metadata": {},
   "source": [
    "### 2. Fetch Data using yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe48747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch daily data for a stock\n",
    "ticker = \"AAPL\"\n",
    "data = yf.download(ticker, start=\"2020-01-01\", end=\"2023-01-01\", interval=\"1d\")\n",
    "\n",
    "# Prepare data for the model\n",
    "data = data.rename(columns={\n",
    "    \"Open\": \"open\",\n",
    "    \"High\": \"high\",\n",
    "    \"Low\": \"low\",\n",
    "    \"Close\": \"close\",\n",
    "    \"Volume\": \"volume\"\n",
    "})\n",
    "data['amount'] = data['close'] * data['volume']\n",
    "data['timestamps'] = data.index\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec290007",
   "metadata": {},
   "source": [
    "### 3. Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction setup\n",
    "lookback = 365\n",
    "pred_len = 90\n",
    "\n",
    "x_df = data.iloc[-lookback-pred_len:-pred_len]\n",
    "y_df_ground_truth = data.iloc[-pred_len:]\n",
    "\n",
    "x_timestamp = x_df['timestamps']\n",
    "y_timestamp = y_df_ground_truth['timestamps']\n",
    "\n",
    "# Make Prediction\n",
    "pred_df = predictor.predict(\n",
    "    df=x_df[['open', 'high', 'low', 'close', 'volume', 'amount']],\n",
    "    x_timestamp=x_timestamp,\n",
    "    y_timestamp=y_timestamp,\n",
    "    pred_len=pred_len,\n",
    "    T=1.0,\n",
    "    top_p=0.9,\n",
    "    sample_count=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Forecasted Data Head:\")\n",
    "print(pred_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616a37",
   "metadata": {},
   "source": [
    "### 4. Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce969a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(historical_df, ground_truth_df, prediction_df):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    plt.plot(historical_df.index, historical_df['close'], label='Historical Data', color='blue')\n",
    "    plt.plot(ground_truth_df.index, ground_truth_df['close'], label='Ground Truth', color='green')\n",
    "    plt.plot(prediction_df.index, prediction_df['close'], label='Prediction', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title(f'{ticker} Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_prediction(x_df, y_df_ground_truth, pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
